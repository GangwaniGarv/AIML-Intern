{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xu1yX5Wo3ehM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('titanic.csv')  # Adjust filename if needed\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumn info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7xyk5jD7GM0",
        "outputId": "195db794-e38a-4eaa-b610-96071e0c01a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (418, 12)\n",
            "\n",
            "Column info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Survived     418 non-null    int64  \n",
            " 2   Pclass       418 non-null    int64  \n",
            " 3   Name         418 non-null    object \n",
            " 4   Sex          418 non-null    object \n",
            " 5   Age          332 non-null    float64\n",
            " 6   SibSp        418 non-null    int64  \n",
            " 7   Parch        418 non-null    int64  \n",
            " 8   Ticket       418 non-null    object \n",
            " 9   Fare         417 non-null    float64\n",
            " 10  Cabin        91 non-null     object \n",
            " 11  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 39.3+ KB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning and preprocessing\n",
        "\n",
        "def clean_titanic_data(df):\n",
        "\n",
        "    data = df.copy() # Creating a copy to avoid modifying the original dataset\n",
        "\n",
        "    # Handling missing values\n",
        "\n",
        "    # Age: Filling the 86 missing values with median age by Pclass and Sex\n",
        "    age_median = data.groupby(['Pclass', 'Sex'])['Age'].median()\n",
        "    for pclass in [1, 2, 3]:\n",
        "        for sex in ['male', 'female']:\n",
        "            mask = (data['Pclass'] == pclass) & (data['Sex'] == sex) & (data['Age'].isnull())\n",
        "            if mask.sum() > 0:  # Only fill if there are missing values for this group\n",
        "                median_age = age_median.get((pclass, sex))\n",
        "                if pd.notna(median_age):\n",
        "                    data.loc[mask, 'Age'] = median_age\n",
        "                else:\n",
        "                    # Fallback to overall median for this group\n",
        "                    data.loc[mask, 'Age'] = data['Age'].median()\n",
        "\n",
        "    # Fare: Filling the 1 missing value with median fare by Pclass\n",
        "    if data['Fare'].isnull().sum() > 0:\n",
        "        fare_median = data.groupby('Pclass')['Fare'].median()\n",
        "        for pclass in [1, 2, 3]:\n",
        "            mask = (data['Pclass'] == pclass) & (data['Fare'].isnull())\n",
        "            if mask.sum() > 0:\n",
        "                data.loc[mask, 'Fare'] = fare_median[pclass]\n",
        "\n",
        "    # Cabin: Extracting deck information and creating binary feature for cabin availability\n",
        "    # Since 327 out of 418 values are missing, we'll create features from available data\n",
        "    data['HasCabin'] = data['Cabin'].notna().astype(int)\n",
        "\n",
        "    # Extract deck letter from cabin (first character)\n",
        "    data['Deck'] = data['Cabin'].str[0]\n",
        "    data['Deck'].fillna('Unknown', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "    # Feature engineering\n",
        "\n",
        "    # Creating family size feature\n",
        "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
        "\n",
        "    # Creating is_alone feature\n",
        "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
        "\n",
        "    # Extracting the title from Name\n",
        "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "    # Grouping rare titles\n",
        "    title_mapping = {\n",
        "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
        "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
        "        'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n",
        "        'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
        "        'Capt': 'Rare', 'Sir': 'Rare'\n",
        "    }\n",
        "    data['Title'] = data['Title'].map(title_mapping)\n",
        "    data['Title'].fillna('Rare', inplace=True)\n",
        "\n",
        "    # Creating age groups\n",
        "    data['AgeGroup'] = pd.cut(data['Age'], bins=[0, 12, 18, 35, 60, 100],\n",
        "                             labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
        "\n",
        "    # Creating fare groups\n",
        "    data['FareGroup'] = pd.qcut(data['Fare'], q=4, labels=['Low', 'Medium', 'High', 'Very_High'])\n",
        "\n",
        "\n",
        "\n",
        "    # Encoding categorical variables\n",
        "\n",
        "    # Binary encoding for Sex\n",
        "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "    # Label encoding for Embarked\n",
        "    le_embarked = LabelEncoder()\n",
        "    data['Embarked'] = le_embarked.fit_transform(data['Embarked'])\n",
        "\n",
        "    # One-hot encoding for Title\n",
        "    title_dummies = pd.get_dummies(data['Title'], prefix='Title')\n",
        "    data = pd.concat([data, title_dummies], axis=1)\n",
        "\n",
        "    # One-hot encoding for AgeGroup\n",
        "    age_dummies = pd.get_dummies(data['AgeGroup'], prefix='AgeGroup')\n",
        "    data = pd.concat([data, age_dummies], axis=1)\n",
        "\n",
        "    # One-hot encoding for FareGroup\n",
        "    fare_dummies = pd.get_dummies(data['FareGroup'], prefix='FareGroup')\n",
        "    data = pd.concat([data, fare_dummies], axis=1)\n",
        "\n",
        "    # One-hot encoding for Deck\n",
        "    deck_dummies = pd.get_dummies(data['Deck'], prefix='Deck')\n",
        "    data = pd.concat([data, deck_dummies], axis=1)\n",
        "\n",
        "    # 4. Drop unnecessary columns\n",
        "    columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Title', 'AgeGroup', 'FareGroup', 'Deck']\n",
        "    data = data.drop(columns=[col for col in columns_to_drop if col in data.columns])\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "1BWKCton7GJ1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data\n",
        "cleaned_df = clean_titanic_data(df)\n",
        "\n",
        "print(\"\\nCleaned dataset shape:\", cleaned_df.shape)\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "missing_after = cleaned_df.isnull().sum()\n",
        "print(missing_after)\n",
        "print(f\"\\nTotal missing values: {missing_after.sum()}\")\n",
        "print(\"\\nFinal columns:\")\n",
        "print(cleaned_df.columns.tolist())\n",
        "\n",
        "# Verify the cleaning worked for the specific missing values\n",
        "print(f\"\\nVerification:\")\n",
        "print(f\"Age missing before: 86, after: {cleaned_df['Age'].isnull().sum()}\")\n",
        "print(f\"Fare missing before: 1, after: {cleaned_df['Fare'].isnull().sum()}\")\n",
        "print(f\"Cabin missing before: 327 (now converted to HasCabin and Deck features)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaEZzJSH7GHE",
        "outputId": "dcfbd2a8-e96d-48dd-c1ed-2c1dd83c80f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned dataset shape: (418, 33)\n",
            "\n",
            "Missing values after cleaning:\n",
            "Survived               0\n",
            "Pclass                 0\n",
            "Sex                    0\n",
            "Age                    0\n",
            "SibSp                  0\n",
            "Parch                  0\n",
            "Fare                   0\n",
            "Embarked               0\n",
            "HasCabin               0\n",
            "FamilySize             0\n",
            "IsAlone                0\n",
            "Title_Master           0\n",
            "Title_Miss             0\n",
            "Title_Mr               0\n",
            "Title_Mrs              0\n",
            "Title_Rare             0\n",
            "AgeGroup_Child         0\n",
            "AgeGroup_Teen          0\n",
            "AgeGroup_Adult         0\n",
            "AgeGroup_Middle        0\n",
            "AgeGroup_Senior        0\n",
            "FareGroup_Low          0\n",
            "FareGroup_Medium       0\n",
            "FareGroup_High         0\n",
            "FareGroup_Very_High    0\n",
            "Deck_A                 0\n",
            "Deck_B                 0\n",
            "Deck_C                 0\n",
            "Deck_D                 0\n",
            "Deck_E                 0\n",
            "Deck_F                 0\n",
            "Deck_G                 0\n",
            "Deck_Unknown           0\n",
            "dtype: int64\n",
            "\n",
            "Total missing values: 0\n",
            "\n",
            "Final columns:\n",
            "['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'HasCabin', 'FamilySize', 'IsAlone', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'AgeGroup_Child', 'AgeGroup_Teen', 'AgeGroup_Adult', 'AgeGroup_Middle', 'AgeGroup_Senior', 'FareGroup_Low', 'FareGroup_Medium', 'FareGroup_High', 'FareGroup_Very_High', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_Unknown']\n",
            "\n",
            "Verification:\n",
            "Age missing before: 86, after: 0\n",
            "Fare missing before: 1, after: 0\n",
            "Cabin missing before: 327 (now converted to HasCabin and Deck features)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-24bb3eaf2443>:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Deck'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-3-24bb3eaf2443>:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Title'].fillna('Rare', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing features and target\n",
        "X = cleaned_df.drop('Survived', axis=1)\n",
        "y = cleaned_df['Survived']\n",
        "\n",
        "# Spliting into train and test sets (80/20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Train samples: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test samples: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fuHPUV47F_L",
        "outputId": "f9740dba-7543-42da-f9e2-c513340691ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set shape: (334, 32)\n",
            "Test set shape: (84, 32)\n",
            "Train samples: 334 (79.9%)\n",
            "Test samples: 84 (20.1%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned datasets\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "train_data.to_csv('titanic_train_cleaned.csv', index=False)\n",
        "test_data.to_csv('titanic_test_cleaned.csv', index=False)\n",
        "cleaned_df.to_csv('titanic_full_cleaned.csv', index=False)\n",
        "\n",
        "print(\"\\nFiles saved:\")\n",
        "print(\"- titanic_train_cleaned.csv\")\n",
        "print(\"- titanic_test_cleaned.csv\")\n",
        "print(\"- titanic_full_cleaned.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flb_W_2t7DRH",
        "outputId": "bb617f4f-f5de-4050-da38-60e985a750c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Files saved:\n",
            "- titanic_train_cleaned.csv\n",
            "- titanic_test_cleaned.csv\n",
            "- titanic_full_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show survival distribution\n",
        "print(f\"\\nSurvival distribution:\")\n",
        "survival_counts = y.value_counts()\n",
        "print(f\"Not survived (0): {survival_counts[0]} ({survival_counts[0]/len(y)*100:.1f}%)\")\n",
        "print(f\"Survived (1): {survival_counts[1]} ({survival_counts[1]/len(y)*100:.1f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8di82Q7-Akt",
        "outputId": "fcc9324e-5732-40ea-8a43-856cb1be9f36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Survival distribution:\n",
            "Not survived (0): 266 (63.6%)\n",
            "Survived (1): 152 (36.4%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic statistics\n",
        "print(\"\\nDataset summary:\")\n",
        "print(cleaned_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yf5j2KW-ET4",
        "outputId": "ddac3be8-a487-4347-eef0-199c634b7295"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset summary:\n",
            "         Survived      Pclass         Sex         Age       SibSp       Parch  \\\n",
            "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000   \n",
            "mean     0.363636    2.265550    0.363636   29.297847    0.447368    0.392344   \n",
            "std      0.481622    0.841838    0.481622   13.038856    0.896760    0.981429   \n",
            "min      0.000000    1.000000    0.000000    0.170000    0.000000    0.000000   \n",
            "25%      0.000000    1.000000    0.000000   22.000000    0.000000    0.000000   \n",
            "50%      0.000000    3.000000    0.000000   25.000000    0.000000    0.000000   \n",
            "75%      1.000000    3.000000    1.000000   36.375000    1.000000    0.000000   \n",
            "max      1.000000    3.000000    1.000000   76.000000    8.000000    9.000000   \n",
            "\n",
            "             Fare    Embarked    HasCabin  FamilySize     IsAlone  \n",
            "count  418.000000  418.000000  418.000000  418.000000  418.000000  \n",
            "mean    35.560845    1.401914    0.217703    1.839713    0.605263  \n",
            "std     55.856972    0.854496    0.413179    1.519072    0.489380  \n",
            "min      0.000000    0.000000    0.000000    1.000000    0.000000  \n",
            "25%      7.895800    1.000000    0.000000    1.000000    0.000000  \n",
            "50%     14.454200    2.000000    0.000000    1.000000    1.000000  \n",
            "75%     31.471875    2.000000    0.000000    2.000000    1.000000  \n",
            "max    512.329200    2.000000    1.000000   11.000000    1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation with survival\n",
        "print(\"\\nTop correlations with Survival:\")\n",
        "correlation = cleaned_df.corr()['Survived'].abs().sort_values(ascending=False)\n",
        "print(correlation.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ybXY62G-HUd",
        "outputId": "45963a24-c629-4b74-b6d0-bd0b237b4268"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top correlations with Survival:\n",
            "Survived               1.000000\n",
            "Sex                    1.000000\n",
            "Title_Mr               0.877762\n",
            "Title_Miss             0.638606\n",
            "Title_Mrs              0.603458\n",
            "IsAlone                0.244187\n",
            "FareGroup_Very_High    0.192853\n",
            "Fare                   0.192225\n",
            "Title_Master           0.173858\n",
            "FamilySize             0.161803\n",
            "Name: Survived, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}